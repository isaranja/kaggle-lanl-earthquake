{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import gc\n",
    "\n",
    "import os\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tqdm_pandas\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Conv1D,MaxPooling1D,GlobalAveragePooling1D,Flatten,AveragePooling1D\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 18749, 4)          132       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 18742, 4)          132       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 6247, 4)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 6240, 8)           264       \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 6233, 8)           520       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 2077, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 2070, 16)          1040      \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 2063, 16)          2064      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 687, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 680, 32)           4128      \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 673, 32)           8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 224, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7168)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7168)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 7169      \n",
      "=================================================================\n",
      "Total params: 23,673\n",
      "Trainable params: 23,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=4 , kernel_size=16, strides=8, activation='relu', input_shape=(150000, 2)))\n",
    "model.add(Conv1D(filters=4, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "\n",
    "model.add(Conv1D(filters=8, kernel_size=8, activation='relu'))\n",
    "model.add(Conv1D(filters=8, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "\n",
    "model.add(Conv1D(filters=16, kernel_size=8, activation='relu'))\n",
    "model.add(Conv1D(filters=16, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.4))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_absolute_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the acousting signals\n",
    "\n",
    "def prepareAd(x):\n",
    "    x = np.sign(x)*np.log(1 + np.abs(x))/8.7\n",
    "    #x = np.sign(x)*np.log(1 + np.sqrt(np.abs(x)))/4.4\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainBatch(dfl):\n",
    "    batch_size = 1024\n",
    "    \n",
    "    x = np.empty([batch_size,150000,2])\n",
    "    y = np.empty([batch_size,1])\n",
    "    \n",
    "    for i,rn in enumerate(np.random.randint(dfl.shape[0]-150000, size=batch_size)):\n",
    "        df = dfl.loc[rn:rn+149999,:]\n",
    "        x[i,:,:] = df.loc[:,['acoustic_data_p','acoustic_data_n']].values\n",
    "        y[i] = df.time_to_failure.values[-1]\n",
    "\n",
    "    return(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0 \t file chunck : 0\t  max_time_to_failure :  11.54\tWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "  loss :  2.47 \t val_loss :  2.39\n",
      "epoch :  0 \t file chunck : 1\t  max_time_to_failure :  14.18\t  loss :  2.22 \t val_loss :  2.2\n",
      "epoch :  0 \t file chunck : 2\t  max_time_to_failure :  8.86\t  loss :  1.76 \t val_loss :  1.75\n",
      "epoch :  0 \t file chunck : 3\t  max_time_to_failure :  12.69\t  loss :  1.63 \t val_loss :  1.58\n",
      "epoch :  0 \t file chunck : 4\t  max_time_to_failure :  8.06\t  loss :  1.46 \t val_loss :  1.43\n",
      "epoch :  0 \t file chunck : 5\t  max_time_to_failure :  7.06\t  loss :  1.36 \t val_loss :  1.33\n",
      "epoch :  0 \t file chunck : 6\t  max_time_to_failure :  16.11\t  loss :  1.46 \t val_loss :  1.43\n",
      "epoch :  0 \t file chunck : 7\t  max_time_to_failure :  7.91\t  loss :  1.38 \t val_loss :  1.33\n",
      "epoch :  0 \t file chunck : 8\t  max_time_to_failure :  9.64\t  loss :  1.33 \t val_loss :  1.29\n",
      "epoch :  0 \t file chunck : 9\t  max_time_to_failure :  11.43\t  loss :  1.31 \t val_loss :  1.27\n",
      "epoch :  0 \t file chunck : 10\t  max_time_to_failure :  11.02\t  loss :  1.28 \t val_loss :  1.27\n",
      "epoch :  0 \t file chunck : 11\t  max_time_to_failure :  8.83\t  loss :  1.24 \t val_loss :  1.24\n",
      "epoch :  0 \t file chunck : 12\t  max_time_to_failure :  8.57\t  loss :  1.2 \t val_loss :  1.2\n",
      "epoch :  0 \t file chunck : 13\t  max_time_to_failure :  14.75\t  loss :  1.26 \t val_loss :  1.24\n",
      "epoch :  0 \t file chunck : 14\t  max_time_to_failure :  9.46\t  loss :  1.25 \t val_loss :  1.23\n",
      "epoch :  1 \t file chunck : 0\t  max_time_to_failure :  11.54\t  loss :  1.17 \t val_loss :  1.18\n",
      "epoch :  1 \t file chunck : 1\t  max_time_to_failure :  14.18\t  loss :  1.15 \t val_loss :  1.16\n",
      "epoch :  1 \t file chunck : 2\t  max_time_to_failure :  8.86\t  loss :  1.15 \t val_loss :  1.14\n",
      "epoch :  1 \t file chunck : 3\t  max_time_to_failure :  12.69\t  loss :  1.15 \t val_loss :  1.17\n",
      "epoch :  1 \t file chunck : 4\t  max_time_to_failure :  8.06\t  loss :  1.15 \t val_loss :  1.16\n",
      "epoch :  1 \t file chunck : 5\t  max_time_to_failure :  7.06\t  loss :  1.14 \t val_loss :  1.16\n",
      "epoch :  1 \t file chunck : 6\t  max_time_to_failure :  16.11\t  loss :  1.13 \t val_loss :  1.14\n",
      "epoch :  1 \t file chunck : 7\t  max_time_to_failure :  7.91\t  loss :  1.13 \t val_loss :  1.14\n",
      "epoch :  1 \t file chunck : 8\t  max_time_to_failure :  9.64\t  loss :  1.12 \t val_loss :  1.14\n",
      "epoch :  1 \t file chunck : 9\t  max_time_to_failure :  11.43\t  loss :  1.11 \t val_loss :  1.13\n",
      "epoch :  1 \t file chunck : 10\t  max_time_to_failure :  11.02\t  loss :  1.12 \t val_loss :  1.13\n",
      "epoch :  1 \t file chunck : 11\t  max_time_to_failure :  8.83\t  loss :  1.12 \t val_loss :  1.12\n",
      "epoch :  1 \t file chunck : 12\t  max_time_to_failure :  8.57\t  loss :  1.12 \t val_loss :  1.13\n",
      "epoch :  1 \t file chunck : 13\t  max_time_to_failure :  14.75\t  loss :  1.1 \t val_loss :  1.14\n",
      "epoch :  1 \t file chunck : 14\t  max_time_to_failure :  9.46\t  loss :  1.1 \t val_loss :  1.14\n",
      "epoch :  2 \t file chunck : 0\t  max_time_to_failure :  11.54\t  loss :  1.1 \t val_loss :  1.15\n",
      "epoch :  2 \t file chunck : 1\t  max_time_to_failure :  14.18\t  loss :  1.1 \t val_loss :  1.14\n",
      "epoch :  2 \t file chunck : 2\t  max_time_to_failure :  8.86\t  loss :  1.09 \t val_loss :  1.15\n",
      "epoch :  2 \t file chunck : 3\t  max_time_to_failure :  12.69\t  loss :  1.09 \t val_loss :  1.14\n",
      "epoch :  2 \t file chunck : 4\t  max_time_to_failure :  8.06\t  loss :  1.09 \t val_loss :  1.13\n",
      "epoch :  2 \t file chunck : 5\t  max_time_to_failure :  7.06\t  loss :  1.09 \t val_loss :  1.14\n",
      "epoch :  2 \t file chunck : 6\t  max_time_to_failure :  16.11\t  loss :  1.08 \t val_loss :  1.16\n",
      "epoch :  2 \t file chunck : 7\t  max_time_to_failure :  7.91\t  loss :  1.08 \t val_loss :  1.17\n",
      "epoch :  2 \t file chunck : 8\t  max_time_to_failure :  9.64\t  loss :  1.09 \t val_loss :  1.17\n",
      "epoch :  2 \t file chunck : 9\t  max_time_to_failure :  11.43\t  loss :  1.08 \t val_loss :  1.17\n",
      "epoch :  2 \t file chunck : 10\t  max_time_to_failure :  11.02\t  loss :  1.08 \t val_loss :  1.16\n",
      "epoch :  2 \t file chunck : 11\t  max_time_to_failure :  8.83\t  loss :  1.07 \t val_loss :  1.16\n",
      "epoch :  2 \t file chunck : 12\t  max_time_to_failure :  8.57\t  loss :  1.07 \t val_loss :  1.16\n",
      "epoch :  2 \t file chunck : 13\t  max_time_to_failure :  14.75\t  loss :  1.07 \t val_loss :  1.14\n",
      "epoch :  2 \t file chunck : 14\t  max_time_to_failure :  9.46\t  loss :  1.07 \t val_loss :  1.14\n",
      "epoch :  3 \t file chunck : 0\t  max_time_to_failure :  11.54\t  loss :  1.06 \t val_loss :  1.11\n",
      "epoch :  3 \t file chunck : 1\t  max_time_to_failure :  14.18\t  loss :  1.06 \t val_loss :  1.12\n",
      "epoch :  3 \t file chunck : 2\t  max_time_to_failure :  8.86\t  loss :  1.06 \t val_loss :  1.14\n",
      "epoch :  3 \t file chunck : 3\t  max_time_to_failure :  12.69\t  loss :  1.06 \t val_loss :  1.13\n",
      "epoch :  3 \t file chunck : 4\t  max_time_to_failure :  8.06\t  loss :  1.06 \t val_loss :  1.15\n",
      "epoch :  3 \t file chunck : 5\t  max_time_to_failure :  7.06\t  loss :  1.06 \t val_loss :  1.15\n",
      "epoch :  3 \t file chunck : 6\t  max_time_to_failure :  16.11\t  loss :  1.06 \t val_loss :  1.16\n",
      "epoch :  3 \t file chunck : 7\t  max_time_to_failure :  7.91\t  loss :  1.07 \t val_loss :  1.15\n",
      "epoch :  3 \t file chunck : 8\t  max_time_to_failure :  9.64\t  loss :  1.06 \t val_loss :  1.16\n",
      "epoch :  3 \t file chunck : 9\t  max_time_to_failure :  11.43\t  loss :  1.07 \t val_loss :  1.17\n",
      "epoch :  3 \t file chunck : 10\t  max_time_to_failure :  11.02\t  loss :  1.07 \t val_loss :  1.17\n",
      "epoch :  3 \t file chunck : 11\t  max_time_to_failure :  8.83\t  loss :  1.07 \t val_loss :  1.19\n",
      "epoch :  3 \t file chunck : 12\t  max_time_to_failure :  8.57\t  loss :  1.07 \t val_loss :  1.18\n",
      "epoch :  3 \t file chunck : 13\t  max_time_to_failure :  14.75\t  loss :  1.07 \t val_loss :  1.18\n",
      "epoch :  3 \t file chunck : 14\t  max_time_to_failure :  9.46\t  loss :  1.07 \t val_loss :  1.18\n",
      "epoch :  4 \t file chunck : 0\t  max_time_to_failure :  11.54\t  loss :  1.06 \t val_loss :  1.19\n",
      "epoch :  4 \t file chunck : 1\t  max_time_to_failure :  14.18\t  loss :  1.06 \t val_loss :  1.18\n",
      "epoch :  4 \t file chunck : 2\t  max_time_to_failure :  8.86\t  loss :  1.06 \t val_loss :  1.17\n",
      "epoch :  4 \t file chunck : 3\t  max_time_to_failure :  12.69\t  loss :  1.06 \t val_loss :  1.18\n",
      "epoch :  4 \t file chunck : 4\t  max_time_to_failure :  8.06\t  loss :  1.06 \t val_loss :  1.16\n",
      "epoch :  4 \t file chunck : 5\t  max_time_to_failure :  7.06\t  loss :  1.06 \t val_loss :  1.16\n",
      "epoch :  4 \t file chunck : 6\t  max_time_to_failure :  16.11\t  loss :  1.06 \t val_loss :  1.16\n",
      "epoch :  4 \t file chunck : 7\t  max_time_to_failure :  7.91\t  loss :  1.06 \t val_loss :  1.15\n",
      "epoch :  4 \t file chunck : 8\t  max_time_to_failure :  9.64\t  loss :  1.07 \t val_loss :  1.16\n",
      "epoch :  4 \t file chunck : 9\t  max_time_to_failure :  11.43\t  loss :  1.07 \t val_loss :  1.13\n",
      "epoch :  4 \t file chunck : 10\t  max_time_to_failure :  11.02\t  loss :  1.06 \t val_loss :  1.13\n",
      "epoch :  4 \t file chunck : 11\t  max_time_to_failure :  8.83\t  loss :  1.06 \t val_loss :  1.11\n",
      "epoch :  4 \t file chunck : 12\t  max_time_to_failure :  8.57\t  loss :  1.06 \t val_loss :  1.11\n",
      "epoch :  4 \t file chunck : 13\t  max_time_to_failure :  14.75\t  loss :  1.05 \t val_loss :  1.11\n",
      "epoch :  4 \t file chunck : 14\t  max_time_to_failure :  9.46\t  loss :  1.04 \t val_loss :  1.11\n",
      "epoch :  5 \t file chunck : 0\t  max_time_to_failure :  11.54\t  loss :  1.04 \t val_loss :  1.1\n",
      "epoch :  5 \t file chunck : 1\t  max_time_to_failure :  14.18\t  loss :  1.04 \t val_loss :  1.1\n",
      "epoch :  5 \t file chunck : 2\t  max_time_to_failure :  8.86\t  loss :  1.04 \t val_loss :  1.09\n",
      "epoch :  5 \t file chunck : 3\t  max_time_to_failure :  12.69\t  loss :  1.04 \t val_loss :  1.08\n",
      "epoch :  5 \t file chunck : 4\t  max_time_to_failure :  8.06\t  loss :  1.04 \t val_loss :  1.08\n",
      "epoch :  5 \t file chunck : 5\t  max_time_to_failure :  7.06\t  loss :  1.04 \t val_loss :  1.08\n",
      "epoch :  5 \t file chunck : 6\t  max_time_to_failure :  16.11\t  loss :  1.03 \t val_loss :  1.07\n",
      "epoch :  5 \t file chunck : 7\t  max_time_to_failure :  7.91\t  loss :  1.03 \t val_loss :  1.08\n",
      "epoch :  5 \t file chunck : 8\t  max_time_to_failure :  9.64\t  loss :  1.03 \t val_loss :  1.08\n",
      "epoch :  5 \t file chunck : 9\t  max_time_to_failure :  11.43\t  loss :  1.03 \t val_loss :  1.08\n",
      "epoch :  5 \t file chunck : 10\t  max_time_to_failure :  11.02\t  loss :  1.03 \t val_loss :  1.09\n",
      "epoch :  5 \t file chunck : 11\t  max_time_to_failure :  8.83\t  loss :  1.03 \t val_loss :  1.1\n",
      "epoch :  5 \t file chunck : 12\t  max_time_to_failure :  8.57\t  loss :  1.04 \t val_loss :  1.08\n",
      "epoch :  5 \t file chunck : 13\t  max_time_to_failure :  14.75\t  loss :  1.05 \t val_loss :  1.1\n",
      "epoch :  5 \t file chunck : 14\t  max_time_to_failure :  9.46\t  loss :  1.06 \t val_loss :  1.11\n",
      "epoch :  6 \t file chunck : 0\t  max_time_to_failure :  11.54\t  loss :  1.06 \t val_loss :  1.1\n",
      "epoch :  6 \t file chunck : 1\t  max_time_to_failure :  14.18\t  loss :  1.06 \t val_loss :  1.1\n",
      "epoch :  6 \t file chunck : 2\t  max_time_to_failure :  8.86\t  loss :  1.06 \t val_loss :  1.11\n",
      "epoch :  6 \t file chunck : 3\t  max_time_to_failure :  12.69\t  loss :  1.06 \t val_loss :  1.12\n",
      "epoch :  6 \t file chunck : 4\t  max_time_to_failure :  8.06\t  loss :  1.06 \t val_loss :  1.13\n",
      "epoch :  6 \t file chunck : 5\t  max_time_to_failure :  7.06\t  loss :  1.06 \t val_loss :  1.13\n",
      "epoch :  6 \t file chunck : 6\t  max_time_to_failure :  16.11\t  loss :  1.06 \t val_loss :  1.12\n",
      "epoch :  6 \t file chunck : 7\t  max_time_to_failure :  7.91\t  loss :  1.06 \t val_loss :  1.11\n",
      "epoch :  6 \t file chunck : 8\t  max_time_to_failure :  9.64\t  loss :  1.06 \t val_loss :  1.12\n",
      "epoch :  6 \t file chunck : 9\t  max_time_to_failure :  11.43\t  loss :  1.04 \t val_loss :  1.12\n",
      "epoch :  6 \t file chunck : 10\t  max_time_to_failure :  11.02\t  loss :  1.04 \t val_loss :  1.1\n",
      "epoch :  6 \t file chunck : 11\t  max_time_to_failure :  8.83\t  loss :  1.04 \t val_loss :  1.09\n",
      "epoch :  6 \t file chunck : 12\t  max_time_to_failure :  8.57\t  loss :  1.04 \t val_loss :  1.1\n",
      "epoch :  6 \t file chunck : 13\t  max_time_to_failure :  14.75\t  loss :  1.04 \t val_loss :  1.07\n",
      "epoch :  6 \t file chunck : 14\t  max_time_to_failure :  9.46\t  loss :  1.03 \t val_loss :  1.06\n",
      "epoch :  7 \t file chunck : 0\t  max_time_to_failure :  11.54\t  loss :  1.03 \t val_loss :  1.08\n",
      "epoch :  7 \t file chunck : 1\t  max_time_to_failure :  14.18\t  loss :  1.02 \t val_loss :  1.08\n",
      "epoch :  7 \t file chunck : 2\t  max_time_to_failure :  8.86\t  loss :  1.02 \t val_loss :  1.08\n",
      "epoch :  7 \t file chunck : 3\t  max_time_to_failure :  12.69\t  loss :  1.02 \t val_loss :  1.09\n",
      "epoch :  7 \t file chunck : 4\t  max_time_to_failure :  8.06\t  loss :  1.02 \t val_loss :  1.07\n",
      "epoch :  7 \t file chunck : 5\t  max_time_to_failure :  7.06\t  loss :  1.02 \t val_loss :  1.08\n",
      "epoch :  7 \t file chunck : 6\t  max_time_to_failure :  16.11\t  loss :  1.02 \t val_loss :  1.06\n",
      "epoch :  7 \t file chunck : 7\t  max_time_to_failure :  7.91\t  loss :  1.02 \t val_loss :  1.07\n",
      "epoch :  7 \t file chunck : 8\t  max_time_to_failure :  9.64\t  loss :  1.02 \t val_loss :  1.07\n",
      "epoch :  7 \t file chunck : 9\t  max_time_to_failure :  11.43\t  loss :  1.03 \t val_loss :  1.07\n",
      "epoch :  7 \t file chunck : 10\t  max_time_to_failure :  11.02\t  loss :  1.03 \t val_loss :  1.07\n",
      "epoch :  7 \t file chunck : 11\t  max_time_to_failure :  8.83\t  loss :  1.03 \t val_loss :  1.09\n",
      "epoch :  7 \t file chunck : 12\t  max_time_to_failure :  8.57\t  loss :  1.03 \t val_loss :  1.09\n",
      "epoch :  7 \t file chunck : 13\t  max_time_to_failure :  14.75\t  loss :  1.03 \t val_loss :  1.1\n",
      "epoch :  7 \t file chunck : 14\t  max_time_to_failure :  9.46\t  loss :  1.03 \t val_loss :  1.09\n",
      "epoch :  8 \t file chunck : 0\t  max_time_to_failure :  11.54\t  loss :  1.04 \t val_loss :  1.09\n",
      "epoch :  8 \t file chunck : 1\t  max_time_to_failure :  14.18\t  loss :  1.04 \t val_loss :  1.09\n",
      "epoch :  8 \t file chunck : 2\t  max_time_to_failure :  8.86\t  loss :  1.04 \t val_loss :  1.11\n",
      "epoch :  8 \t file chunck : 3\t  max_time_to_failure :  12.69\t  loss :  1.05 \t val_loss :  1.09\n",
      "epoch :  8 \t file chunck : 4\t  max_time_to_failure :  8.06\t  loss :  1.05 \t val_loss :  1.09\n",
      "epoch :  8 \t file chunck : 5\t  max_time_to_failure :  7.06\t  loss :  1.05 \t val_loss :  1.07\n",
      "epoch :  8 \t file chunck : 6\t  max_time_to_failure :  16.11\t  loss :  1.05 \t val_loss :  1.07\n",
      "epoch :  8 \t file chunck : 7\t  max_time_to_failure :  7.91\t  loss :  1.05 \t val_loss :  1.07\n",
      "epoch :  8 \t file chunck : 8\t  max_time_to_failure :  9.64\t  loss :  1.06 \t val_loss :  1.07\n",
      "epoch :  8 \t file chunck : 9\t  max_time_to_failure :  11.43\t  loss :  1.06 \t val_loss :  1.07\n",
      "epoch :  8 \t file chunck : 10\t  max_time_to_failure :  11.02\t  loss :  1.05 \t val_loss :  1.08\n",
      "epoch :  8 \t file chunck : 11\t  max_time_to_failure :  8.83\t  loss :  1.06 \t val_loss :  1.09\n",
      "epoch :  8 \t file chunck : 12\t  max_time_to_failure :  8.57\t  loss :  1.05 \t val_loss :  1.09\n",
      "epoch :  8 \t file chunck : 13\t  max_time_to_failure :  14.75\t  loss :  1.06 \t val_loss :  1.13\n",
      "epoch :  8 \t file chunck : 14\t  max_time_to_failure :  9.46\t  loss :  1.06 \t val_loss :  1.12\n",
      "epoch :  9 \t file chunck : 0\t  max_time_to_failure :  11.54\t  loss :  1.06 \t val_loss :  1.12\n",
      "epoch :  9 \t file chunck : 1\t  max_time_to_failure :  14.18\t  loss :  1.05 \t val_loss :  1.13\n",
      "epoch :  9 \t file chunck : 2\t  max_time_to_failure :  8.86\t  loss :  1.05 \t val_loss :  1.11\n",
      "epoch :  9 \t file chunck : 3\t  max_time_to_failure :  12.69\t  loss :  1.04 \t val_loss :  1.12\n",
      "epoch :  9 \t file chunck : 4\t  max_time_to_failure :  8.06\t  loss :  1.04 \t val_loss :  1.12\n",
      "epoch :  9 \t file chunck : 5\t  max_time_to_failure :  7.06\t  loss :  1.04 \t val_loss :  1.12\n",
      "epoch :  9 \t file chunck : 6\t  max_time_to_failure :  16.11\t  loss :  1.04 \t val_loss :  1.14\n",
      "epoch :  9 \t file chunck : 7\t  max_time_to_failure :  7.91\t  loss :  1.04 \t val_loss :  1.13\n",
      "epoch :  9 \t file chunck : 8\t  max_time_to_failure :  9.64\t  loss :  1.04 \t val_loss :  1.12\n",
      "epoch :  9 \t file chunck : 9\t  max_time_to_failure :  11.43\t  loss :  1.04 \t val_loss :  1.14\n",
      "epoch :  9 \t file chunck : 10\t  max_time_to_failure :  11.02\t  loss :  1.04 \t val_loss :  1.13\n",
      "epoch :  9 \t file chunck : 11\t  max_time_to_failure :  8.83\t  loss :  1.04 \t val_loss :  1.13\n",
      "epoch :  9 \t file chunck : 12\t  max_time_to_failure :  8.57\t  loss :  1.04 \t val_loss :  1.12\n",
      "epoch :  9 \t file chunck : 13\t  max_time_to_failure :  14.75\t  loss :  1.04 \t val_loss :  1.1\n",
      "epoch :  9 \t file chunck : 14\t  max_time_to_failure :  9.46\t  loss :  1.03 \t val_loss :  1.11\n"
     ]
    }
   ],
   "source": [
    "srows = [5656574,50085878,104677356,138772453,187641820,218652630,245829585,307838917,\n",
    " 338276287,375377848,419368880,461811623,495800225,528777115,585568144]\n",
    "\n",
    "nrows = [44429304,54591478,34095097,48869367,31010810,27176955,62009332,30437370,\n",
    "         37101561,43991032,42442743,33988602,32976890,56791029,36417529]\n",
    "\n",
    "loss = []\n",
    "val_loss = [] \n",
    "\n",
    "for epoch in range(10):\n",
    "    for i, (s,n) in enumerate(zip(srows,nrows)):\n",
    "        print('epoch : ' , epoch,'\\t file chunck :',i, end = '\\t')\n",
    "\n",
    "        train_df = pd.read_csv(\"../input/train.csv\",\n",
    "                           skiprows = s,\n",
    "                           nrows = n,\n",
    "                          )\n",
    "        train_df.columns = ['acoustic_data','time_to_failure']\n",
    "\n",
    "        print('  max_time_to_failure : ',np.round(train_df.time_to_failure.values[0],2) , end = '\\t')\n",
    "\n",
    "        # scaling\n",
    "        train_df.acoustic_data = prepareAd(train_df.acoustic_data.values)\n",
    "        train_df.time_to_failure = train_df.time_to_failure\n",
    "\n",
    "        # two series\n",
    "        train_df['acoustic_data_p'] = np.where(train_df['acoustic_data']>=0, np.abs(train_df['acoustic_data']), 0)\n",
    "        train_df['acoustic_data_n'] = np.where(train_df['acoustic_data']<0, np.abs(train_df['acoustic_data']), 0)\n",
    "\n",
    "        x_train,y_train = getTrainBatch(train_df)\n",
    "\n",
    "        history = model.fit(x_train,\n",
    "                         y_train,\n",
    "                         batch_size=16,\n",
    "                         epochs=10,\n",
    "                         validation_split=0.1,\n",
    "                         verbose=0)\n",
    "        \n",
    "        loss = loss + history.history['loss']\n",
    "        val_loss = val_loss + history.history['val_loss']\n",
    "        \n",
    "        print('  loss : ',np.round(mean(loss[-150:]),2), '\\t val_loss : ', np.round(mean(val_loss[-150:]),2))\n",
    "        \n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the submission\n",
    "def predictSubmission(seg_id):\n",
    "    test_df = pd.read_csv('../input/test/' + seg_id + '.csv')\n",
    "    \n",
    "    test_df.acoustic_data =prepareAd(test_df.acoustic_data.values) \n",
    "\n",
    "    # two series\n",
    "    test_df['acoustic_data_p'] = np.where(test_df['acoustic_data']>=0, np.abs(test_df['acoustic_data']), 0)\n",
    "    test_df['acoustic_data_n'] = np.where(test_df['acoustic_data']<0, np.abs(test_df['acoustic_data']), 0)\n",
    "\n",
    "    # reshaping\n",
    "    x_test = test_df.loc[:,['acoustic_data_p','acoustic_data_n']].values.reshape(-1,150000,2)\n",
    "    \n",
    "    y = model.predict(x_test)\n",
    "    return y[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83a599ec3f4440e921165361cbd8bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tqdm_pandas(tqdm())\n",
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "submission.loc[:,'time_to_failure']=submission.loc[:,'seg_id'].progress_apply(predictSubmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2624.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.053779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.388977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.252201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.167432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.355411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.906939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.952302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time_to_failure\n",
       "count      2624.000000\n",
       "mean          4.053779\n",
       "std           2.388977\n",
       "min          -1.252201\n",
       "25%           2.167432\n",
       "50%           3.355411\n",
       "75%           5.906939\n",
       "max           9.952302"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[submission.time_to_failure <0,'time_to_failure'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_15.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission_15.csv' target='_blank'>submission_15.csv</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/submission_15.csv"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('submission_15.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
